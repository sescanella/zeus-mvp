---
phase: 07-data-model-foundation
plan: 04
type: execute
wave: 3
depends_on: [07-03]
files_modified: [backend/scripts/validate_schema_startup.py, tests/integration/test_schema_validation.py]
autonomous: true
user_setup: []

must_haves:
  truths:
    - "System validates all sheet schemas at startup"
    - "System fails fast if critical columns missing"
    - "Validation covers all three sheets"
  artifacts:
    - path: "backend/scripts/validate_schema_startup.py"
      provides: "Standalone schema validation"
      min_lines: 100
    - path: "tests/integration/test_schema_validation.py"
      provides: "Integration tests"
      min_lines: 80
  key_links:
    - from: "validate_schema_startup.py"
      to: "ColumnMapCache"
      via: "critical column validation"
      pattern: "validate_critical_columns"
---

<objective>
Create comprehensive schema validation script for v4.0 columns.

Purpose: Fail fast at startup rather than runtime if schema migration is incomplete
Output: Robust validation script that prevents v4.0 from running with v3.0 schema
</objective>

<execution_context>
@/Users/sescanella/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sescanella/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-data-model-foundation/07-RESEARCH.md
@.planning/phases/07-data-model-foundation/07-01-SUMMARY.md
@.planning/phases/07-data-model-foundation/07-02-SUMMARY.md
@.planning/phases/07-data-model-foundation/07-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create comprehensive schema validation script</name>
  <files>backend/scripts/validate_schema_startup.py</files>
  <action>
    Create a validation script that checks all sheets have required v4.0 columns.

    The script must validate:

    1. **Operaciones sheet (72 columns)**:
       - v3.0 columns (0-67): TAG_SPOOL through Estado_Detalle
       - v4.0 additions (68-72): Total_Uniones, Uniones_ARM_Completadas, Uniones_SOLD_Completadas, Pulgadas_ARM, Pulgadas_SOLD

    2. **Uniones sheet (18 columns)**:
       - Core: ID, TAG_SPOOL, N_UNION, DN_UNION, TIPO_UNION
       - ARM: ARM_FECHA_INICIO, ARM_FECHA_FIN, ARM_WORKER
       - SOLD: SOL_FECHA_INICIO, SOL_FECHA_FIN, SOL_WORKER
       - NDT: NDT_FECHA, NDT_STATUS
       - Audit: version, Creado_Por, Fecha_Creacion, Modificado_Por, Fecha_Modificacion

    3. **Metadata sheet (11 columns)**:
       - v3.0 columns (1-10): ID through Metadata_JSON
       - v4.0 addition (11): N_UNION

    The script should:
    - Use ColumnMapCache.validate_critical_columns() method
    - Return structured validation result (OK/FAIL per sheet)
    - Support being called from main.py startup hook
    - Log detailed errors about missing columns
    - Exit with error code 1 if validation fails

    Can be run standalone: `python backend/scripts/validate_schema_startup.py`

    Example structure:
    ```python
    def validate_v4_schema() -> tuple[bool, dict]:
        """Validate all sheets have v4.0 schema.

        Returns:
            (success, details) where details = {sheet_name: {status, missing}}
        """
        results = {}

        # Validate Operaciones
        required = ["Total_Uniones", "Uniones_ARM_Completadas", ...]
        ok, missing = ColumnMapCache.validate_critical_columns("Operaciones", required)
        results["Operaciones"] = {"status": "OK" if ok else "FAIL", "missing": missing}

        # Similar for Uniones and Metadata...

        all_ok = all(r["status"] == "OK" for r in results.values())
        return all_ok, results
    ```
  </action>
  <verify>python backend/scripts/validate_schema_startup.py && echo "Validation passed" || echo "Validation failed"</verify>
  <done>Script runs and reports validation status for all three sheets</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests for schema validation</name>
  <files>tests/integration/test_schema_validation.py</files>
  <action>
    Create integration tests that verify startup validation works correctly.

    Test cases:
    1. test_startup_fails_missing_operaciones_columns()
       - Mock Operaciones with only 67 columns
       - Verify RuntimeError raised with "Total_Uniones" in message

    2. test_startup_fails_missing_uniones_sheet()
       - Mock missing Uniones sheet
       - Verify RuntimeError raised

    3. test_startup_fails_missing_metadata_column()
       - Mock Metadata with only 10 columns
       - Verify RuntimeError raised with "N_UNION" in message

    4. test_startup_succeeds_all_columns_present()
       - Mock all sheets with correct columns
       - Verify no exception raised

    Use unittest.mock to mock SheetsRepository responses.
    Test the actual validation logic, not full FastAPI startup.
  </action>
  <verify>PYTHONPATH="$(pwd)" pytest tests/integration/test_schema_validation.py -v</verify>
  <done>All validation tests pass</done>
</task>

</tasks>

<verification>
1. Run standalone validation: `python backend/scripts/validate_schema_startup.py`
2. Run tests: `PYTHONPATH="$(pwd)" pytest tests/integration/test_schema_validation.py`
</verification>

<success_criteria>
- [ ] Validation script checks all 3 sheets comprehensively
- [ ] Script can be called standalone or imported
- [ ] Clear error messages identify missing columns
- [ ] Integration tests verify failure scenarios
</success_criteria>

<output>
After completion, create `.planning/phases/07-data-model-foundation/07-04-SUMMARY.md`
</output>