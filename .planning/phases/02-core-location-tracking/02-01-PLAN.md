---
phase: 02-core-location-tracking
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/requirements.txt
  - backend/config.py
  - backend/repositories/redis_repository.py
  - backend/services/redis_lock_service.py
  - backend/exceptions/occupation_errors.py
  - backend/core/dependency.py
autonomous: true
must_haves:
  truths:
    - "Redis client can connect to Redis instance"
    - "Lock service can acquire atomic locks with SET NX EX pattern"
    - "Lock service can safely release locks with Lua script verification"
    - "Lock expiration prevents permanent spool locking"
  artifacts:
    - path: "backend/repositories/redis_repository.py"
      provides: "Redis connection management with async support"
      min_lines: 50
    - path: "backend/services/redis_lock_service.py"
      provides: "Atomic lock operations for spool occupation"
      exports: ["RedisLockService", "acquire_lock", "release_lock"]
    - path: "backend/exceptions/occupation_errors.py"
      provides: "SpoolOccupiedError and VersionConflictError exceptions"
      contains: "class SpoolOccupiedError"
  key_links:
    - from: "backend/services/redis_lock_service.py"
      to: "redis.asyncio"
      via: "SET NX EX atomic operation"
      pattern: "redis\\.set.*nx=True.*ex="
    - from: "backend/services/redis_lock_service.py"
      to: "Lua script"
      via: "Safe lock release with ownership check"
      pattern: "redis\\.eval.*RELEASE_SCRIPT"
---

<objective>
Deploy Redis infrastructure for atomic spool locking and implement lock service with SET NX EX pattern

Purpose: Establish foundation for race condition prevention in concurrent TOMAR operations
Output: Redis repository, lock service, and occupation error handling ready for use
</objective>

<execution_context>
@/Users/sescanella/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sescanella/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-location-tracking/02-CONTEXT.md
@.planning/phases/02-core-location-tracking/02-RESEARCH.md

# Reference existing backend structure
@backend/config.py
@backend/core/dependency.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Redis client and update dependencies</name>
  <files>backend/requirements.txt, backend/config.py</files>
  <action>
    Add Redis async client with hiredis C extension for performance:
    - Add `redis[hiredis]==5.0.1` to requirements.txt (NOT aioredis - that's deprecated)
    - Add `tenacity==8.2.3` for retry logic with exponential backoff
    - Add Redis configuration to config.py:
      - REDIS_URL from environment (default: redis://localhost:6379)
      - REDIS_LOCK_TTL_SECONDS (default: 3600 - 1 hour)
      - REDIS_MAX_CONNECTIONS (default: 50)

    Use environment variable pattern consistent with existing GOOGLE_SHEET_ID pattern.
  </action>
  <verify>pip list | grep redis shows redis 5.0.1 installed</verify>
  <done>Redis client installed and config.py has Redis settings with defaults</done>
</task>

<task type="auto">
  <name>Task 2: Create Redis repository for connection management</name>
  <files>backend/repositories/redis_repository.py, backend/core/dependency.py</files>
  <action>
    Create RedisRepository class with async connection management:
    - Singleton pattern to reuse connection pool across requests
    - Connection pool with max_connections from config
    - Async connect() and disconnect() methods for app lifecycle
    - Health check method to verify Redis connectivity
    - Error handling for connection failures with appropriate logging

    Register in dependency.py for FastAPI dependency injection:
    - Create get_redis_client() dependency function
    - Integrate with app startup/shutdown events

    Follow existing patterns from sheets_repository.py for consistency.
  </action>
  <verify>grep -n "class RedisRepository" backend/repositories/redis_repository.py shows class definition</verify>
  <done>RedisRepository manages connection pool and integrates with FastAPI lifecycle</done>
</task>

<task type="auto">
  <name>Task 3: Implement Redis lock service with atomic operations</name>
  <files>backend/services/redis_lock_service.py, backend/exceptions/occupation_errors.py</files>
  <action>
    Create RedisLockService with atomic lock operations:

    1. Create occupation_errors.py with custom exceptions:
       - SpoolOccupiedError(tag_spool, owner_id, owner_name)
       - VersionConflictError(expected, actual, message)
       - LockExpiredError(tag_spool)

    2. Implement RedisLockService class:
       - acquire_lock(tag_spool, worker_id, worker_nombre): SET NX EX pattern
         - Lock key format: "spool_lock:{tag_spool}"
         - Lock value format: "{worker_id}:{uuid4}" for unique token
         - TTL: 3600 seconds (1 hour) from config
         - On conflict: raise SpoolOccupiedError with current owner

       - release_lock(tag_spool, lock_token): Lua script for safe release
         - Only delete if lock value matches our token (prevents accidental release)
         - Return True if released, False if not our lock

       - extend_lock(tag_spool, lock_token, additional_seconds): For long operations
         - Check ownership before extending
         - Update TTL without changing lock value

       - get_lock_owner(tag_spool): Query current lock owner for error messages
         - Parse "{worker_id}:{token}" format
         - Return None if not locked

    Include RELEASE_SCRIPT Lua code from research (lines 233-240).
    Use tenacity for retry logic on transient Redis errors.
  </action>
  <verify>grep -n "class RedisLockService" backend/services/redis_lock_service.py shows class definition at specific line number</verify>
  <done>RedisLockService provides atomic lock operations with ownership verification and can be verified via grep</done>
</task>

</tasks>

<verification>
1. Redis client connects successfully to configured URL
2. Lock acquisition uses atomic SET NX EX preventing race conditions
3. Lock release verifies ownership before deletion
4. Locks auto-expire after 1 hour preventing permanent locks
5. Service handles Redis connection errors gracefully
</verification>

<success_criteria>
- Redis repository establishes and manages connection pool
- Lock service implements SET NX EX pattern correctly
- Custom exceptions provide clear error context
- FastAPI can inject Redis client via dependency
- All components follow existing backend patterns
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-location-tracking/02-01-SUMMARY.md`
</output>