---
phase: 02-core-location-tracking
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/models/occupation.py
  - backend/services/occupation_service.py
  - backend/routers/occupation.py
  - backend/main.py
autonomous: true
must_haves:
  truths:
    - "Worker can TOMAR available spool via POST endpoint"
    - "Worker can PAUSAR occupied spool they own"
    - "Worker can COMPLETAR spool and mark operation complete"
    - "System prevents TOMAR of already occupied spools"
    - "Metadata logs all occupation events for audit trail"
  artifacts:
    - path: "backend/models/occupation.py"
      provides: "Pydantic models for occupation requests/responses"
      contains: "class TomarRequest"
    - path: "backend/services/occupation_service.py"
      provides: "Business logic for TOMAR/PAUSAR/COMPLETAR operations"
      exports: ["OccupationService", "tomar", "pausar", "completar"]
    - path: "backend/routers/occupation.py"
      provides: "REST endpoints for occupation operations"
      contains: "@router.post('/tomar')"
  key_links:
    - from: "backend/services/occupation_service.py"
      to: "sheets_repository"
      via: "Update Ocupado_Por column"
      pattern: "sheets_repository\\.update_spool.*Ocupado_Por"
    - from: "backend/services/occupation_service.py"
      to: "metadata_repository"
      via: "Log occupation events"
      pattern: "metadata_repository\\.log_event.*TOMAR"
---

<objective>
Implement OccupationService with TOMAR/PAUSAR/COMPLETAR business logic and REST endpoints

Purpose: Core operations for workers to take, pause, and complete work on spools
Output: Working API endpoints that enforce occupation constraints and log events
</objective>

<execution_context>
@/Users/sescanella/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sescanella/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-location-tracking/02-CONTEXT.md
@.planning/phases/02-core-location-tracking/02-RESEARCH.md

# Reference existing patterns
@backend/services/action_service.py
@backend/services/validation_service.py
@backend/repositories/sheets_repository.py
@backend/repositories/metadata_repository.py
@backend/models/spool.py
@backend/models/worker.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create occupation models for API contracts</name>
  <files>backend/models/occupation.py</files>
  <action>
    Create Pydantic models for occupation operations:

    1. Request models:
       - TomarRequest(tag_spool: str, worker_id: int, worker_nombre: str, operacion: OperacionEnum)
       - PausarRequest(tag_spool: str, worker_id: int, worker_nombre: str)
       - CompletarRequest(tag_spool: str, worker_id: int, worker_nombre: str, fecha_operacion: date)
       - BatchTomarRequest(tag_spools: List[str], worker_id, worker_nombre, operacion)

    2. Response models:
       - OccupationResponse(success: bool, tag_spool: str, message: str)
       - BatchOccupationResponse(total: int, succeeded: int, failed: int, details: List[OccupationResponse])
       - OccupationStatus(tag_spool: str, ocupado: bool, ocupado_por: Optional[str], fecha_ocupacion: Optional[datetime])

    3. Internal models:
       - OccupationEvent for metadata logging
       - LockToken for Redis lock tracking

    Use existing enums from models/enums.py (OperacionEnum, AccionEnum).
    Follow existing Pydantic patterns from models/action.py.
  </action>
  <verify>grep "class TomarRequest" backend/models/occupation.py shows model definition</verify>
  <done>Occupation models define clear API contracts for all operations</done>
</task>

<task type="auto">
  <name>Task 2: Implement OccupationService with core business logic</name>
  <files>backend/services/occupation_service.py</files>
  <action>
    Create OccupationService orchestrating lock service, sheets, and metadata:

    1. TOMAR operation:
       - Validate spool exists and has Fecha_Materiales (prerequisite)
       - Acquire Redis lock (will fail if already occupied)
       - Update Ocupado_Por and Fecha_Ocupacion in Operaciones sheet
       - Import MetadataRepository, call metadata_repository.log_event(evento_tipo="TOMAR_{operacion}", tag_spool=tag_spool, worker_id=worker_id, worker_nombre=worker_nombre, operacion=operacion, accion="TOMAR", fecha_operacion=date.today(), metadata_json=json.dumps({"lock_token": lock_token}))
       - Return success with "Spool {tag} tomado por {worker}"

    2. PAUSAR operation:
       - Verify worker owns the lock (compare Redis lock owner)
       - Update spool state column in Operaciones sheet:
         * For ARM operation: update Estado_Armado column to "ARM parcial (pausado)"
         * For SOLD operation: update Estado_Soldado column to "SOLD parcial (pausado)"
       - Clear Ocupado_Por and Fecha_Ocupacion columns
       - Release Redis lock
       - Import MetadataRepository, call metadata_repository.log_event(evento_tipo="PAUSAR_{operacion}", tag_spool=tag_spool, worker_id=worker_id, worker_nombre=worker_nombre, operacion=operacion, accion="PAUSAR", metadata_json=json.dumps({"estado": estado_value}))
       - Return success with "Trabajo pausado en {tag}"

    3. COMPLETAR operation:
       - Verify worker owns the lock
       - Update fecha_armado or fecha_soldadura based on operation
       - Clear Ocupado_Por and Fecha_Ocupacion
       - Release Redis lock
       - Import MetadataRepository, call metadata_repository.log_event(evento_tipo="COMPLETAR_{operacion}", tag_spool=tag_spool, worker_id=worker_id, worker_nombre=worker_nombre, operacion=operacion, accion="COMPLETAR", fecha_operacion=fecha_operacion, metadata_json=json.dumps({"completed": True}))
       - Return success with "Operaci√≥n completada en {tag}"

    4. Batch TOMAR:
       - Process each spool independently
       - Collect success/failure for each
       - Return BatchOccupationResponse with details
       - Example: "7 of 10 succeeded, 3 failed: [reasons]"

    Import statements at top:
    ```python
    from backend.repositories.metadata_repository import MetadataRepository
    from backend.repositories.sheets_repository import SheetsRepository
    from backend.services.redis_lock_service import RedisLockService
    import json
    from datetime import date
    ```

    Inject dependencies: RedisLockService, SheetsRepository, MetadataRepository.
    Handle SpoolOccupiedError and return 409 Conflict status.
    Use worker name format "INICIALES(ID)" from existing patterns.
  </action>
  <verify>grep "class OccupationService" backend/services/occupation_service.py shows service class</verify>
  <done>OccupationService orchestrates locks, sheets updates with state marking, and metadata logging with proper imports</done>
</task>

<task type="auto">
  <name>Task 3: Create REST endpoints for occupation operations</name>
  <files>backend/routers/occupation.py, backend/main.py</files>
  <action>
    1. Create occupation router with endpoints:
       - POST /api/occupation/tomar - Take single spool
       - POST /api/occupation/pausar - Pause work on spool
       - POST /api/occupation/completar - Complete work on spool
       - POST /api/occupation/batch-tomar - Take multiple spools
       - GET /api/occupation/status/{tag_spool} - Check occupation status

    2. Endpoint implementation:
       - Inject OccupationService via Depends()
       - Handle business exceptions and map to HTTP status:
         - SpoolOccupiedError -> 409 Conflict
         - ValidationError -> 400 Bad Request
         - SpoolNotFoundError -> 404 Not Found
       - Add OpenAPI documentation with examples

    3. Register router in main.py:
       - Import occupation router
       - Add to app with prefix="/api/occupation"
       - Update CORS settings if needed

    Follow existing router patterns from routers/actions.py.
    Use consistent error response format from existing endpoints.
  </action>
  <verify>curl -X POST http://localhost:8000/api/occupation/tomar returns method not allowed (endpoint exists)</verify>
  <done>REST endpoints expose occupation operations with proper error handling</done>
</task>

</tasks>

<verification>
1. TOMAR endpoint accepts request and updates Ocupado_Por column
2. PAUSAR clears occupation and marks state as "ARM parcial (pausado)" or "SOLD parcial (pausado)"
3. COMPLETAR updates fecha column and releases lock
4. Batch TOMAR processes multiple spools with partial success
5. All operations log events to Metadata sheet with proper imports and method signatures
6. 409 Conflict returned when spool already occupied
</verification>

<success_criteria>
- OccupationService implements all three core operations
- Redis locks prevent concurrent TOMAR on same spool
- PAUSAR properly marks spool state as paused in Estado columns
- Metadata maintains complete audit trail with explicit import/call patterns
- API follows RESTful conventions
- Error messages clearly indicate occupation conflicts
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-location-tracking/02-02-SUMMARY.md`
</output>