---
phase: 02-core-location-tracking
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - backend/models/occupation.py
  - backend/services/occupation_service.py
  - backend/routers/occupation.py
  - backend/main.py
autonomous: true
must_haves:
  truths:
    - "Worker can TOMAR available spool via POST endpoint"
    - "Worker can PAUSAR occupied spool they own"
    - "Worker can COMPLETAR spool and mark operation complete"
    - "System prevents TOMAR of already occupied spools"
    - "Metadata logs all occupation events for audit trail"
  artifacts:
    - path: "backend/models/occupation.py"
      provides: "Pydantic models for occupation requests/responses"
      contains: "class TomarRequest"
    - path: "backend/services/occupation_service.py"
      provides: "Business logic for TOMAR/PAUSAR/COMPLETAR operations"
      exports: ["OccupationService", "tomar", "pausar", "completar"]
    - path: "backend/routers/occupation.py"
      provides: "REST endpoints for occupation operations"
      contains: "@router.post('/tomar')"
  key_links:
    - from: "backend/services/occupation_service.py"
      to: "sheets_repository"
      via: "Update Ocupado_Por column"
      pattern: "sheets_repository\\.update_spool.*Ocupado_Por"
    - from: "backend/services/occupation_service.py"
      to: "metadata_repository"
      via: "Log occupation events"
      pattern: "metadata_repository\\.log_event.*TOMAR"
    - from: "backend/routers/occupation.py"
      to: "409 HTTP status"
      via: "SpoolOccupiedError mapping in exception handler"
      pattern: "except SpoolOccupiedError.*409"
---

<objective>
Implement OccupationService with TOMAR/PAUSAR/COMPLETAR business logic and REST endpoints

Purpose: Core operations for workers to take, pause, and complete work on spools
Output: Working API endpoints that enforce occupation constraints and log events
</objective>

<execution_context>
@/Users/sescanella/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sescanella/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-location-tracking/02-CONTEXT.md
@.planning/phases/02-core-location-tracking/02-RESEARCH.md

# Reference Redis lock service from 02-01
@.planning/phases/02-core-location-tracking/02-01-SUMMARY.md

# Reference existing patterns
@backend/services/action_service.py
@backend/services/validation_service.py
@backend/repositories/sheets_repository.py
@backend/repositories/metadata_repository.py
@backend/models/spool.py
@backend/models/worker.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create occupation models for API contracts</name>
  <files>backend/models/occupation.py</files>
  <action>
    Create Pydantic models for occupation operations:

    1. Request models:
       - TomarRequest(tag_spool: str, worker_id: int, worker_nombre: str, operacion: OperacionEnum)
       - PausarRequest(tag_spool: str, worker_id: int, worker_nombre: str)
       - CompletarRequest(tag_spool: str, worker_id: int, worker_nombre: str, fecha_operacion: date)
       - BatchTomarRequest(tag_spools: List[str], worker_id, worker_nombre, operacion)

    2. Response models:
       - OccupationResponse(success: bool, tag_spool: str, message: str)
       - BatchOccupationResponse(total: int, succeeded: int, failed: int, details: List[OccupationResponse])
       - OccupationStatus(tag_spool: str, ocupado: bool, ocupado_por: Optional[str], fecha_ocupacion: Optional[datetime])

    3. Internal models:
       - OccupationEvent for metadata logging
       - LockToken for Redis lock tracking

    Use existing enums from models/enums.py (OperacionEnum, AccionEnum).
    Follow existing Pydantic patterns from models/action.py.
  </action>
  <verify>grep "class TomarRequest" backend/models/occupation.py shows model definition</verify>
  <done>Occupation models define clear API contracts for all operations</done>
</task>

<task type="auto">
  <name>Task 2: Implement OccupationService with core business logic</name>
  <files>backend/services/occupation_service.py</files>
  <action>
    Create OccupationService orchestrating lock service, sheets, and metadata:

    Constructor dependency injection:
    ```python
    def __init__(
        self,
        redis_lock_service: RedisLockService,
        sheets_repository: SheetsRepository,
        metadata_repository: MetadataRepository
    ):
        self.redis_lock_service = redis_lock_service
        self.sheets_repository = sheets_repository
        self.metadata_repository = metadata_repository
    ```

    1. TOMAR operation:
       - Validate spool exists and has Fecha_Materiales (prerequisite)
       - Acquire Redis lock using RedisLockService from 02-01 (will fail if already occupied)
       - Update Ocupado_Por and Fecha_Ocupacion in Operaciones sheet
       - Call metadata_repository.log_event(evento_tipo="TOMAR_{operacion}", tag_spool=tag_spool, worker_id=worker_id, worker_nombre=worker_nombre, operacion=operacion, accion="TOMAR", fecha_operacion=date.today(), metadata_json=json.dumps({"lock_token": lock_token}))
       - Return success with "Spool {tag} tomado por {worker}"
       - On SpoolOccupiedError: re-raise for router to map to 409

    2. PAUSAR operation:
       - Verify worker owns the lock (compare Redis lock owner)
       - Update spool state in Operaciones sheet:
         * Add new column "Estado_Ocupacion" (or reuse existing status column per v3.0 schema)
         * Set value to "ARM parcial (pausado)" for ARM or "SOLD parcial (pausado)" for SOLD
         * Note: The exact column name will be determined based on v3.0 schema (may be new column or existing status column)
       - Clear Ocupado_Por and Fecha_Ocupacion columns
       - Release Redis lock
       - Call metadata_repository.log_event(evento_tipo="PAUSAR_{operacion}", tag_spool=tag_spool, worker_id=worker_id, worker_nombre=worker_nombre, operacion=operacion, accion="PAUSAR", metadata_json=json.dumps({"estado": estado_value}))
       - Return success with "Trabajo pausado en {tag}"

    3. COMPLETAR operation:
       - Verify worker owns the lock
       - Update fecha_armado or fecha_soldadura based on operation
       - Clear Ocupado_Por and Fecha_Ocupacion
       - Release Redis lock
       - Call metadata_repository.log_event(evento_tipo="COMPLETAR_{operacion}", tag_spool=tag_spool, worker_id=worker_id, worker_nombre=worker_nombre, operacion=operacion, accion="COMPLETAR", fecha_operacion=fecha_operacion, metadata_json=json.dumps({"completed": True}))
       - Return success with "Operaci√≥n completada en {tag}"

    4. Batch TOMAR:
       - Process each spool independently
       - Collect success/failure for each
       - Return BatchOccupationResponse with details
       - Example: "7 of 10 succeeded, 3 failed: [reasons]"

    Import statements at top:
    ```python
    from backend.repositories.metadata_repository import MetadataRepository
    from backend.repositories.sheets_repository import SheetsRepository
    from backend.services.redis_lock_service import RedisLockService
    from backend.exceptions.occupation_errors import SpoolOccupiedError
    import json
    from datetime import date
    ```

    Use worker name format "INICIALES(ID)" from existing patterns.
  </action>
  <verify>grep "class OccupationService" backend/services/occupation_service.py shows service class</verify>
  <done>OccupationService orchestrates locks with proper DI, sheets updates with flexible state marking, and metadata logging</done>
</task>

<task type="auto">
  <name>Task 3: Create REST endpoints for occupation operations with 409 mapping</name>
  <files>backend/routers/occupation.py, backend/main.py</files>
  <action>
    1. Create occupation router with endpoints:
       - POST /api/occupation/tomar - Take single spool
       - POST /api/occupation/pausar - Pause work on spool
       - POST /api/occupation/completar - Complete work on spool
       - POST /api/occupation/batch-tomar - Take multiple spools
       - GET /api/occupation/status/{tag_spool} - Check occupation status

    2. Endpoint implementation with explicit 409 mapping:
       - Inject OccupationService via Depends()
       - Handle business exceptions and map to HTTP status codes:
         ```python
         @router.post("/tomar")
         async def tomar_spool(request: TomarRequest, service: OccupationService = Depends()):
             try:
                 return await service.tomar(request)
             except SpoolOccupiedError as e:
                 # LOC-04 requirement: Return 409 Conflict for race conditions
                 raise HTTPException(status_code=409, detail=str(e))
             except ValidationError as e:
                 raise HTTPException(status_code=400, detail=str(e))
             except SpoolNotFoundError as e:
                 raise HTTPException(status_code=404, detail=str(e))
         ```
       - Add OpenAPI documentation with examples

    3. Register router in main.py:
       - Import occupation router
       - Add to app with prefix="/api/occupation"
       - Update CORS settings if needed

    Follow existing router patterns from routers/actions.py.
    Use consistent error response format from existing endpoints.
  </action>
  <verify>curl -X POST http://localhost:8000/api/occupation/tomar returns method not allowed (endpoint exists)</verify>
  <done>REST endpoints expose occupation operations with explicit 409 mapping for SpoolOccupiedError (LOC-04)</done>
</task>

</tasks>

<verification>
1. TOMAR endpoint accepts request and updates Ocupado_Por column
2. PAUSAR clears occupation and marks state in appropriate column per v3.0 schema
3. COMPLETAR updates fecha column and releases lock
4. Batch TOMAR processes multiple spools with partial success
5. All operations log events to Metadata sheet with proper DI pattern
6. 409 Conflict explicitly returned when spool already occupied (LOC-04)
</verification>

<success_criteria>
- OccupationService implements all three core operations with proper DI
- Redis locks from 02-01 prevent concurrent TOMAR on same spool
- PAUSAR properly marks spool state as paused (column TBD per schema)
- Metadata maintains complete audit trail with injected repository
- API follows RESTful conventions with explicit 409 mapping
- Error messages clearly indicate occupation conflicts
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-location-tracking/02-02-SUMMARY.md`
</output>