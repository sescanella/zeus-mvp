---
phase: 02-core-location-tracking
plan: 04
type: tdd
wave: 3
depends_on: ["02-01", "02-02", "02-03"]
files_modified:
  - tests/integration/test_race_conditions.py
  - tests/unit/test_redis_lock_service.py
  - tests/unit/test_occupation_service.py
  - tests/unit/test_conflict_service.py
autonomous: true
must_haves:
  truths:
    - "10 concurrent TOMAR requests result in 1 success, 9 conflicts"
    - "Lock acquisition is truly atomic under high concurrency"
    - "Version conflicts are detected and retried correctly"
    - "System maintains consistency with parallel operations"
  artifacts:
    - path: "tests/integration/test_race_conditions.py"
      provides: "Race condition validation with concurrent requests"
      contains: "test_concurrent_tomar_prevents_double_booking"
    - path: "tests/unit/test_redis_lock_service.py"
      provides: "Unit tests for Redis lock operations"
      contains: "test_acquire_lock_atomic"
    - path: "tests/unit/test_occupation_service.py"
      provides: "Unit tests for occupation business logic"
      contains: "test_tomar_validates_prerequisites"
  key_links:
    - from: "tests/integration/test_race_conditions.py"
      to: "asyncio.gather"
      via: "Concurrent request simulation"
      pattern: "asyncio\\.gather.*concurrent_tomar"
---

<objective>
Create comprehensive test suite validating race condition prevention and concurrent operation safety

Purpose: Prove system correctly handles concurrent TOMAR attempts and maintains consistency
Output: Test suite that validates atomic locking, version conflicts, and race condition handling
</objective>

<execution_context>
@/Users/sescanella/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sescanella/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-location-tracking/02-CONTEXT.md

# Reference implementations from previous plans
@.planning/phases/02-core-location-tracking/02-01-SUMMARY.md
@.planning/phases/02-core-location-tracking/02-02-SUMMARY.md
@.planning/phases/02-core-location-tracking/02-03-SUMMARY.md
</context>

<feature>
  <name>Race condition prevention test suite</name>
  <files>tests/integration/test_race_conditions.py, tests/unit/test_redis_lock_service.py, tests/unit/test_occupation_service.py, tests/unit/test_conflict_service.py</files>
  <behavior>
    Concurrent TOMAR attempts:
    - Input: 10 parallel TOMAR requests for same spool
    - Output: 1 success (200), 9 conflicts (409)
    - Verification: Only one Ocupado_Por value in sheet

    Lock atomicity:
    - Input: SET NX EX command with same key from 2 clients
    - Output: Exactly one acquires lock
    - Verification: Redis GET shows single owner

    Version conflict retry:
    - Input: Conflicting version on first attempt
    - Output: Retry succeeds with new version
    - Verification: 2 attempts logged, final success

    PAUSAR ownership:
    - Input: Worker A pauses Worker B's spool
    - Output: 403 Forbidden
    - Verification: Lock remains with Worker B

    Batch partial success:
    - Input: 10 spools, 3 already occupied
    - Output: "7 succeeded, 3 failed"
    - Verification: Exactly 7 locks acquired
  </behavior>
  <implementation>
    Use pytest-asyncio for async test support.
    Mock Redis for unit tests, real Redis for integration.
    Use asyncio.gather() to simulate true concurrency.
    Implement deterministic test data for reproducibility.
  </implementation>
</feature>

<tasks>

<task type="auto">
  <name>Task 1: Write failing integration test for concurrent TOMAR</name>
  <files>tests/integration/test_race_conditions.py</files>
  <action>
    Create integration test that validates race condition prevention:

    ```python
    import asyncio
    import pytest
    from httpx import AsyncClient

    @pytest.mark.asyncio
    async def test_concurrent_tomar_prevents_double_booking():
        """10 workers try to TOMAR same spool simultaneously."""
        tag_spool = "TEST-RACE-001"

        async def attempt_tomar(worker_id: int):
            async with AsyncClient(base_url="http://localhost:8000") as client:
                response = await client.post("/api/occupation/tomar", json={
                    "tag_spool": tag_spool,
                    "worker_id": worker_id,
                    "worker_nombre": f"Worker{worker_id}",
                    "operacion": "ARM"
                })
                return response.status_code

        # Launch 10 concurrent requests
        tasks = [attempt_tomar(i) for i in range(1, 11)]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Exactly 1 success, 9 conflicts
        success_count = sum(1 for r in results if r == 200)
        conflict_count = sum(1 for r in results if r == 409)

        assert success_count == 1, f"Expected 1 success, got {success_count}"
        assert conflict_count == 9, f"Expected 9 conflicts, got {conflict_count}"
    ```

    Add similar tests for:
    - Concurrent PAUSAR (only owner succeeds)
    - Concurrent COMPLETAR (only owner succeeds)
    - Batch TOMAR with overlapping spools
    - Version conflict under load
  </action>
  <verify>pytest tests/integration/test_race_conditions.py::test_concurrent_tomar_prevents_double_booking -v (should FAIL initially - before implementation)</verify>
  <done>Integration test initially fails, proving we need race condition prevention</done>
</task>

<task type="auto">
  <name>Task 2: Write unit tests for Redis lock service</name>
  <files>tests/unit/test_redis_lock_service.py</files>
  <action>
    Create unit tests for RedisLockService:

    ```python
    @pytest.mark.asyncio
    async def test_acquire_lock_atomic():
        """Lock acquisition is atomic - only one succeeds."""
        redis_mock = AsyncMock()
        redis_mock.set.return_value = True  # First attempt succeeds

        service = RedisLockService(redis_mock)

        # First acquisition succeeds
        result = await service.acquire_lock("TAG-001", 1, "Worker1")
        assert result is True

        # Second acquisition fails
        redis_mock.set.return_value = False
        with pytest.raises(SpoolOccupiedError) as exc:
            await service.acquire_lock("TAG-001", 2, "Worker2")
        assert "already occupied" in str(exc.value)
    ```

    Test cases:
    - acquire_lock success and failure paths
    - release_lock with correct and incorrect tokens
    - extend_lock for long operations
    - Lock expiration after TTL
    - Redis connection failure handling
    - Lua script execution for safe release
  </action>
  <verify>pytest tests/unit/test_redis_lock_service.py -v</verify>
  <done>Redis lock service unit tests validate atomic operations</done>
</task>

<task type="auto">
  <name>Task 3: Write unit tests for occupation and conflict services</name>
  <files>tests/unit/test_occupation_service.py, tests/unit/test_conflict_service.py</files>
  <action>
    1. OccupationService tests:
       - TOMAR validates Fecha_Materiales prerequisite
       - TOMAR acquires lock before sheet update
       - PAUSAR verifies ownership before clearing
       - COMPLETAR updates correct date column
       - Batch TOMAR returns partial success details
       - Metadata events logged for all operations

    2. ConflictService tests:
       - Version token generation creates unique UUIDs
       - Version mismatch triggers VersionConflictError
       - Retry with exponential backoff on conflict
       - Maximum retry attempts respected
       - Jitter applied to prevent thundering herd
       - Conflict metrics tracked correctly

    Use unittest.mock for dependencies.
    Test both success and failure paths.
    Verify error messages are user-friendly.
  </action>
  <verify>pytest tests/unit/test_occupation_service.py tests/unit/test_conflict_service.py -v</verify>
  <done>Unit tests cover business logic and conflict handling</done>
</task>

<task type="auto">
  <name>Task 4: Verify integration test passes after implementation</name>
  <files>tests/integration/test_race_conditions.py</files>
  <action>
    After Plans 01-03 are complete, verify the race condition test now passes:

    1. Run the integration test again to confirm it passes:
       ```bash
       pytest tests/integration/test_race_conditions.py::test_concurrent_tomar_prevents_double_booking -v
       ```

    2. Expected output:
       - Test should PASS (green)
       - 1 success (200 status)
       - 9 conflicts (409 status)
       - No race conditions detected

    3. If test still fails:
       - Check Redis lock implementation
       - Verify atomic SET NX EX usage
       - Confirm conflict handling in OccupationService
       - Review version token validation

    4. Run full integration suite to ensure all race condition scenarios pass:
       ```bash
       pytest tests/integration/test_race_conditions.py -v
       ```

    5. Expected results:
       - test_concurrent_tomar_prevents_double_booking: PASSED
       - test_concurrent_pausar_only_owner_succeeds: PASSED
       - test_concurrent_completar_only_owner_succeeds: PASSED
       - test_batch_tomar_partial_success: PASSED
       - test_version_conflict_retry: PASSED
  </action>
  <verify>pytest tests/integration/test_race_conditions.py -v (all tests should PASS after implementation complete)</verify>
  <done>Integration tests confirm race condition prevention works correctly with 1 success and 9 conflicts</done>
</task>

</tasks>

<verification>
1. Race condition test initially FAILS proving the problem exists
2. After implementation, test PASSES with exactly 1 success and 9 conflicts
3. Redis lock tests validate atomic SET NX EX behavior
4. Occupation service tests verify business rules
5. Conflict service tests confirm retry logic works
6. All tests pass consistently (no flaky tests)
</verification>

<success_criteria>
- Integration test demonstrates race condition prevention
- Initial test failure proves problem exists
- Final test success confirms solution works
- Unit tests achieve >90% coverage of new code
- Tests run in <10 seconds total
- No hardcoded test data that could become stale
- Clear test names describing what's being validated
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-location-tracking/02-04-SUMMARY.md`
</output>