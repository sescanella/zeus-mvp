# Plan: Implement Batch Update Methods for ARM and SOLD Operations

---
phase: 08-backend-data-layer
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
- backend/repositories/union_repository.py
- tests/unit/test_union_repository_batch.py
autonomous: true

must_haves:
  truths:
    - "Batch update operations complete in single API call (not N calls)"
    - "ARM unions can be marked complete with worker and timestamp"
    - "SOLD unions require ARM completion before they can be completed"
  artifacts:
    - path: "backend/repositories/union_repository.py"
      provides: "batch_update_arm and batch_update_sold methods"
      contains: "batch_update_arm|batch_update_sold"
    - path: "tests/unit/test_union_repository_batch.py"
      provides: "Unit tests for batch operations"
      min_lines: 100
  key_links:
    - from: "batch_update_arm"
      to: "worksheet.batch_update"
      via: "single API call for N unions"
      pattern: "worksheet\\.batch_update\\(batch_data"
    - from: "batch methods"
      to: "cache invalidation"
      via: "invalidate_cache after updates"
      pattern: "invalidate_cache.*_sheet_name"
---

<objective>
Implement batch update methods for ARM and SOLD operations using gspread.batch_update() for performance optimization.

Purpose: Enable updating multiple unions in a single API call instead of individual updates that would take 6+ seconds.
Output: UnionRepository with batch_update_arm and batch_update_sold methods that can update 10 unions in < 1 second.
</objective>

<execution_context>
@/Users/sescanella/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sescanella/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-backend-data-layer/08-CONTEXT.md
@backend/repositories/union_repository.py
@backend/utils/date_formatter.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement batch_update_arm method</name>
  <files>backend/repositories/union_repository.py</files>
  <action>
    Add batch_update_arm method to UnionRepository:
    - Method signature: batch_update_arm(ot: str, union_ids: list[str], worker: str, timestamp: datetime) -> int
    - Query Uniones sheet directly by OT column (Column B) using ColumnMapCache
    - Filter to unions matching the OT value - OT is THE foreign key relationship, NOT TAG_SPOOL
    - Validate each union_id exists and ARM_FECHA_FIN is None
    - Build batch_data using ColumnMapCache for ARM_FECHA_FIN and ARM_WORKER columns
    - Convert column indices to A1 notation (e.g., row 5 col 8 -> "H5")
    - Format timestamp using format_datetime_for_sheets(timestamp)
    - Execute worksheet.batch_update(batch_data, value_input_option='USER_ENTERED')
    - Call self.sheets_repo.invalidate_cache(self._sheet_name) after update
    - Return count of successfully updated unions
    - Apply retry_on_sheets_error decorator for 429 handling
  </action>
  <verify>Method exists and uses OT column directly, not TAG_SPOOL</verify>
  <done>batch_update_arm returns count of updated unions, cache invalidation called, unit tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Implement batch_update_sold method</name>
  <files>backend/repositories/union_repository.py</files>
  <action>
    Add batch_update_sold method to UnionRepository:
    - Method signature: batch_update_sold(ot: str, union_ids: list[str], worker: str, timestamp: datetime) -> int
    - Query Uniones sheet directly by OT column (Column B) using ColumnMapCache
    - Validate ARM_FECHA_FIN is not None (ARM must be completed first)
    - Update SOL_FECHA_FIN and SOL_WORKER columns using batch_update
    - Call self.sheets_repo.invalidate_cache(self._sheet_name) after update
    - Return count of successfully updated unions
  </action>
  <verify>Method validates ARM completion before SOLD update</verify>
  <done>batch_update_sold enforces ARM prerequisite, returns update count, cache invalidated</done>
</task>

<task type="auto">
  <name>Task 3: Add helper method _find_union_row</name>
  <files>backend/repositories/union_repository.py</files>
  <action>
    Add _find_union_row helper method:
    - Method signature: _find_union_row(union_id: str) -> Optional[int]
    - Read Uniones sheet data using self.sheets_repo.get_all()
    - Use ColumnMapCache to find ID column index
    - Search for row where ID matches union_id
    - Return 1-based row number for Google Sheets or None if not found
  </action>
  <verify>Helper method correctly finds row numbers for batch updates</verify>
  <done>_find_union_row returns correct 1-based row numbers for A1 notation</done>
</task>

<task type="auto">
  <name>Task 4: Add validation helper _validate_unions_for_update</name>
  <files>backend/repositories/union_repository.py</files>
  <action>
    Add _validate_unions_for_update helper:
    - Method signature: _validate_unions_for_update(ot: str, union_ids: list[str], operacion: Literal["ARM", "SOLD"]) -> tuple[list[Union], list[str]]
    - Query Uniones directly by OT column (Column B) to get fresh data
    - For each union_id, validate existence and state:
      - ARM: ARM_FECHA_FIN must be None
      - SOLD: ARM_FECHA_FIN not None, SOL_FECHA_FIN is None
    - Return (valid_unions, error_messages) tuple
    - Log warnings for invalid unions but don't fail entire batch
  </action>
  <verify>Validation correctly filters unions by state requirements</verify>
  <done>Validation returns valid unions and logs warnings for invalid ones</done>
</task>

<task type="auto">
  <name>Task 5: Create comprehensive unit tests</name>
  <files>tests/unit/test_union_repository_batch.py</files>
  <action>
    Create test file with comprehensive coverage:
    - Test batch_update_arm with 1, 5, 10 unions
    - Test batch_update_sold with ARM-completed unions
    - Test validation failures (already completed, missing unions)
    - Test SOLD requires ARM completion validation
    - Mock SheetsRepository to verify batch_update called once, not N times
    - Verify correct A1 notation ranges generated
    - Test cache invalidation called after updates
    - Test retry on 429 rate limit errors
    - Test idempotency (calling twice has no side effects)
    - CRITICAL: Verify all operations use OT as THE foreign key, not TAG_SPOOL
  </action>
  <verify>pytest tests/unit/test_union_repository_batch.py -xvs passes</verify>
  <done>All batch update tests pass, confirming single API call optimization</done>
</task>

</tasks>

<verification>
Run unit tests to verify batch update implementation:
```bash
source venv/bin/activate
python -m pytest tests/unit/test_union_repository_batch.py -xvs
```

Verify the implementation meets requirements:
- Batch operations use single worksheet.batch_update() call
- Methods query Uniones by OT column directly (not TAG_SPOOL)
- Cache invalidation happens after every update
- Validation correctly handles state requirements
</verification>

<success_criteria>
- [ ] batch_update_arm and batch_update_sold use single batch_update() API call
- [ ] Methods query Uniones by OT column (Column B) directly
- [ ] Validation ensures ARM completion before SOLD
- [ ] Cache invalidation called after every batch update
- [ ] Unit tests verify batch operations are truly batched (1 call, not N)
</success_criteria>

<output>
After completion, create `.planning/phases/08-backend-data-layer/08-01-SUMMARY.md`
</output>